{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baby Cry CNN Audio Classification :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing the necessary plugins\n",
    "\n",
    "Plugins : keras (tensorflow-gpu backend), sklearn\n",
    "\n",
    "GPU : GTX 980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation and Spliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = np.load('feat.npy')\n",
    "y = np.load('label.npy').ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=233)\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a conv VGGish model or load model with weights if already trained :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(193, 1)))\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(3))\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(trainable=True, filters=64, use_bias=True, bias_regularizer=None, input_dtype=\"float32\", batch_input_shape=[None, 193..., activation=\"relu\", kernel_initializer=\"glorot_uniform\", kernel_constraint=None, activity_regularizer=None, input_shape=(None, Non..., padding=\"valid\", strides=1, name=\"convolution1d_15\", bias_constraint=None, kernel_regularizer=None, kernel_size=3)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_initializer=\"glorot_uniform\", kernel_constraint=None, activity_regularizer=None, trainable=True, input_shape=(None, Non..., padding=\"valid\", strides=1, filters=64, use_bias=True, name=\"convolution1d_16\", bias_regularizer=None, bias_constraint=None, kernel_regularizer=None, activation=\"relu\", kernel_size=3)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(gamma_regularizer=None, name=\"batchnormalization_10\", epsilon=0.001, trainable=True, beta_regularizer=None, momentum=0.99, axis=-1)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(name=\"maxpooling1d_4\", trainable=True, pool_size=3, padding=\"valid\", strides=3)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_initializer=\"glorot_uniform\", kernel_constraint=None, activity_regularizer=None, trainable=True, input_shape=(None, Non..., padding=\"valid\", strides=1, filters=128, use_bias=True, name=\"convolution1d_17\", bias_regularizer=None, bias_constraint=None, kernel_regularizer=None, activation=\"relu\", kernel_size=3)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(gamma_regularizer=None, name=\"batchnormalization_11\", epsilon=0.001, trainable=True, beta_regularizer=None, momentum=0.99, axis=-1)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_initializer=\"glorot_uniform\", kernel_constraint=None, activity_regularizer=None, trainable=True, input_shape=(None, Non..., padding=\"valid\", strides=1, filters=128, use_bias=True, name=\"convolution1d_18\", bias_regularizer=None, bias_constraint=None, kernel_regularizer=None, activation=\"relu\", kernel_size=3)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(gamma_regularizer=None, name=\"batchnormalization_12\", epsilon=0.001, trainable=True, beta_regularizer=None, momentum=0.99, axis=-1)`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3, trainable=True, name=\"dropout_4\")`\n",
      "  return cls(**config)\n",
      "/home/yash/Fabrik/local/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(name=\"dense_4\", bias_regularizer=None, bias_constraint=None, activity_regularizer=None, trainable=True, kernel_constraint=None, kernel_regularizer=None, input_dim=128, units=1, kernel_initializer=\"glorot_uniform\", use_bias=True, activation=\"sigmoid\")`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model_1.h5\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = keras.utils.to_categorical(y_train-1, num_classes=2)\n",
    "#y_test = keras.utils.to_categorical(y_test-1, num_classes=2)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and evaluating : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092/1092 [==============================] - 1s     \n",
      "('Train score (loss):', 0.007024563466586746)\n",
      "('Train accuracy:', 0.9993891264508247)\n",
      "('Test score (loss):', 0.04980642542318908)\n",
      "('Test accuracy:', 0.9844322344322345)\n"
     ]
    }
   ],
   "source": [
    "#print keras.__version__\n",
    "#model.fit(X_train, y_train, batch_size=8, nb_epoch=100)\n",
    "train_score, train_acc = model.evaluate(X_train, y_train, batch_size=8)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=8)\n",
    "\n",
    "print('Train score (loss):', train_score)\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test score (loss):', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and weights  (important) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "counter += 1\n",
    "model.save_weights(\"model_\" + str(counter) + \".h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
